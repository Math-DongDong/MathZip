import streamlit as st
import pandas as pd
import re
from itertools import zip_longest
from wordcloud import WordCloud     # ì›Œë“œí´ë¼ìš°ë“œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import matplotlib.pyplot as plt     # ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬
import os # ë§¨ ìœ„ì— import ì¶”ê°€ í•„ìš”

# ==============================================================================
# 1. í˜ì´ì§€ ì„¤ì • ë° ìŠ¤íƒ€ì¼
# ==============================================================================
st.markdown("""
<style>
    .word-badge {
        display: inline-block;
        background-color: #f0f2f6;
        color: #31333F;
        border: 1px solid #d6d6d8;
        border-radius: 15px; 
        padding: 5px 12px;
        margin: 4px;
        font-size: 14px;
        font-weight: 500;
        box-shadow: 1px 1px 3px rgba(0,0,0,0.1);
        transition: transform 0.2s;
    }
    .word-badge:hover {
        transform: scale(1.05); 
        background-color: #e0e2e6;
        border-color: #ff4b4b; 
        cursor: pointer;
    }
    .bag-container {
        border: 2px dashed #ff4b4b;
        border-radius: 10px;
        padding: 20px;
        background-color: #fff9f9;
        text-align: center;
        min-height: 150px;
    }
    th {
        text-align: center !important;
        background-color: #e8f4f8 !important;
    }
    td {
        text-align: center !important;
        font-family: 'Courier New', monospace; /* ë²¡í„° ëŠë‚Œ */
        font-weight: bold;
        font-size: 16px;
    }
</style>
""", unsafe_allow_html=True)

st.title("ğŸ‘œ í…ìŠ¤íŠ¸ ë°ì´í„°ì˜ í‘œí˜„ê³¼ ì£¼ì œì–´ ì°¾ê¸°")

# ==============================================================================
# 2. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# ==============================================================================
if "combined_df" not in st.session_state:
    st.session_state.combined_df = None

if "confirmed_df" not in st.session_state:
    st.session_state.confirmed_df = None

# ==============================================================================
# 3. í…ìŠ¤íŠ¸ ì…ë ¥ í¼ 
# ==============================================================================
with st.expander("ğŸ” í…ìŠ¤íŠ¸ ë°ì´í„° ì…ë ¥ ì—´ê¸°/ë‹«ê¸°", expanded=True):
    with st.form("three_text_form", border=False):
        c1, c2, c3 = st.columns(3)
        with c1:
            text_a = st.text_area("í…ìŠ¤íŠ¸ A", value="í’ë¯¸ ê¹Šì€ ìŒì‹ê³¼ í¸ì•ˆí•˜ê³  ì•„ëŠ‘í•œ ë¶„ìœ„ê¸°ê°€ ì¡°í™”ë¡­ê²Œ ì–´ìš°ëŸ¬ì§€ëŠ” íŠ¹ë³„í•˜ê²Œ ë§Œë“¤ì–´ì£¼ëŠ” ê³³ì´ì—ìš”.", height=80)
        with c2:
            text_b = st.text_area("í…ìŠ¤íŠ¸ B", value="ë§›ì€ ì •ë§ í›Œë¥­í–ˆì§€ë§Œ, ì§ì›ì˜ ì‘ëŒ€ê°€ ë‹¤ì†Œ ë¯¸ìˆ™í•˜ê³  ì£¼ë¬¸í•œ ìŒì‹ì´ ëŠ¦ê²Œ ë‚˜ì™€ì„œ ì‹¤ë§ìŠ¤ëŸ¬ì› ì–´ìš”~", height=80)
        with c3:
            text_c = st.text_area("í…ìŠ¤íŠ¸ C", value="ê°•ë ¥ ì¶”ì²œ! ìŒì‹ì´ ê¸°ëŒ€ ì´ìƒì´ì—ˆê³ , íŠ¹íˆ ì •ì„±ì´ ëŠê»´ì§€ëŠ” í”Œë ˆì´íŒ…ì€ ê°ë™ ê·¸ ìì²´ì˜€ìŠµë‹ˆë‹¤.", height=80)
        
        submitted = st.form_submit_button("ğŸš€ ë°ì´í„° ì „ì²˜ë¦¬", type="primary", width="stretch")

        if submitted:
            def tokenize(text):
                cleaned = re.sub(r'[^\w\s]', '', text) 
                return cleaned.split()

            tokens_a = tokenize(text_a)
            tokens_b = tokenize(text_b)
            tokens_c = tokenize(text_c)

            combined_data = list(zip_longest(tokens_a, tokens_b, tokens_c, fillvalue=None))
            
            df = pd.DataFrame(combined_data, columns=["í…ìŠ¤íŠ¸ A", "í…ìŠ¤íŠ¸ B", "í…ìŠ¤íŠ¸ C"])
            df.index = df.index + 1
            
            # ë°ì´í„° ì´ˆê¸°í™”
            st.session_state.combined_df = df
            st.session_state.confirmed_df = None 
            st.rerun()

# ==============================================================================
# 4. ë©”ì¸ í™”ë©´
# ==============================================================================
if st.session_state.combined_df is not None:
    
    col_left, col_right = st.columns([0.5, 0.5], gap="large")
    
    # --- [ì™¼ìª½] ì—ë””í„° (í¼ ì ìš©) ---
    with col_left:
        st.subheader("1ï¸âƒ£ ë¶ˆìš©ì–´ ì œê±°")
        st.caption("ë‹¨ì–´ë¥¼ ììœ ë¡­ê²Œ ìˆ˜ì •í•œ ë’¤ ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
        
        with st.form("editor_form", border=False):
            edited_snapshot = st.data_editor(
                st.session_state.combined_df,
                num_rows="delete",
                height=300, 
                key="main_editor"
            )
            
            make_bag_btn = st.form_submit_button("ğŸ’ ë‹¨ì–´ ê°€ë°© ë§Œë“¤ê¸°", type="primary", width="stretch")

        if make_bag_btn:
            st.session_state.combined_df = edited_snapshot
            st.session_state.confirmed_df = edited_snapshot.copy()
            st.rerun()

    # --- [ì˜¤ë¥¸ìª½] ë‹¨ì–´ ê°€ë°© ---
    with col_right:
        if st.session_state.confirmed_df is not None:
            st.subheader("2ï¸âƒ£ ë‹¨ì–´ ê°€ë°©")
            st.caption("ë¶ˆìš©ì–´ê°€ ì œê±°ëœ ìµœì¢… ë‹¨ì–´ ì§‘í•©ì…ë‹ˆë‹¤.")

            target_df = st.session_state.confirmed_df
            
            all_tokens = target_df.stack().dropna().tolist()
            valid_tokens = [t for t in all_tokens if str(t).strip() != ""]
            vocab = sorted(list(set(valid_tokens)))
            
            if vocab:
                html_badges = ""
                for word in vocab:
                    count = valid_tokens.count(word)
                    html_badges += f'<span class="word-badge">{word} <small>({count})</small></span>'
                
                st.markdown(f"""
                <div class="bag-container">
                    <h4>ğŸ‘œBag of Words</h4>
                    <div style="margin-top: 15px;">
                        {html_badges}
                    </div>
                </div>
                """, unsafe_allow_html=True)
            else:
                st.warning("ë‹¨ì–´ ê°€ë°©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        
        else:
            st.info("ğŸ‘ˆ ì™¼ìª½ì—ì„œ ìˆ˜ì •ì„ ë§ˆì¹˜ê³  **'ë‹¨ì–´ ê°€ë°© ë§Œë“¤ê¸°'** ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

    # ==========================================================================
    # 5. í•˜ë‹¨ ë²¡í„° í‘œí˜„ ë° ì›Œë“œ í´ë¼ìš°ë“œ
    # ==========================================================================
    if st.session_state.confirmed_df is not None:
        target_df = st.session_state.confirmed_df
        
        all_tokens = target_df.stack().dropna().tolist()
        valid_tokens = [t for t in all_tokens if str(t).strip() != ""]
        vocab = sorted(list(set(valid_tokens)))

        if vocab:
            st.divider()
            
            # --- ê³µí†µ ë°ì´í„° ì¤€ë¹„ ---
            def get_column_tokens(column_name):
                col_data = target_df[column_name].dropna().tolist()
                return [t for t in col_data if str(t).strip() != ""]

            tokens_list_a = get_column_tokens("í…ìŠ¤íŠ¸ A")
            tokens_list_b = get_column_tokens("í…ìŠ¤íŠ¸ B")
            tokens_list_c = get_column_tokens("í…ìŠ¤íŠ¸ C")

            # --- [ì„¹ì…˜ A] ì›-í•« ë²¡í„° (ì¡´ì¬ ì—¬ë¶€ 1/0) ---
            st.subheader("3ï¸âƒ£ ì›-í•« ë²¡í„° í‘œí˜„ (One-Hot Vector)")
            st.caption("ë‹¨ì–´ ê°€ë°©ì˜ ë‹¨ì–´ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ 1, ì—†ìœ¼ë©´ 0ìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.")

            def make_one_hot(tokens, vocabulary):
                return [1 if word in tokens else 0 for word in vocabulary]

            df_onehot = pd.DataFrame(
                [make_one_hot(tokens_list_a, vocab), 
                 make_one_hot(tokens_list_b, vocab), 
                 make_one_hot(tokens_list_c, vocab)],
                columns=vocab,
                index=["A", "B", "C"]
            )

            # [ì‹œê°í™” í•¨ìˆ˜] ë²¡í„° ìŠ¤íƒ€ì¼ (ê´„í˜¸ ë° ì‰¼í‘œ) ì ìš©
            def format_vector_df(df):
                df_str = df.astype(str)
                for col in df_str.columns[:-1]:
                    df_str[col] = df_str[col] + ","
                df_str.insert(0, " ", "(")
                df_str.insert(len(df_str.columns), "  ", ")")
                return df_str

            st.table(format_vector_df(df_onehot),border="horizontal")

            st.divider()

            st.subheader("4ï¸âƒ£ ë¹ˆë„ìˆ˜ ë²¡í„° í‘œí˜„ (Frequency Vector)")
            st.caption("ê° ë‹¨ì–´ê°€ ë¬¸ì¥ì— ëª‡ ë²ˆ ë“±ì¥í–ˆëŠ”ì§€ë¥¼ í†µí•´ ì£¼ì œì–´ë¥¼ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

            def make_count_vector(tokens, vocabulary):
                return [tokens.count(word) for word in vocabulary]

            df_count = pd.DataFrame(
                [make_count_vector(tokens_list_a, vocab), 
                    make_count_vector(tokens_list_b, vocab), 
                    make_count_vector(tokens_list_c, vocab)],
                columns=vocab,
                index=["A", "B", "C"]
            )
            
            # ì›-í•« ë²¡í„°ì™€ ë™ì¼í•œ ìŠ¤íƒ€ì¼ ì ìš©
            st.table(format_vector_df(df_count),border="horizontal")

            with st.container(horizontal=True):
                st.space("stretch")
                with st.popover("ì›Œë“œí´ë¼ìš°ë“œ ë³´ê¸°",help="ë‹¨ì–´ë“¤ì˜ ë¹ˆë„ìˆ˜ë¥¼ ì‹œê°ì ìœ¼ë¡œ í‘œí˜„í•©ë‹ˆë‹¤.",type ="secondary",width="content"):
                    
                    # ì›Œë“œ í´ë¼ìš°ë“œ ìƒì„±
                    try:
                        # ë¹ˆë„ìˆ˜ ë”•ì…”ë„ˆë¦¬ ìƒì„±
                        total_counts = {word: valid_tokens.count(word) for word in vocab}

                        # í°íŠ¸ ì„¤ì •
                        # 1. í˜„ì¬ íŒŒì¼ì˜ ìœ„ì¹˜ ( .../mathzip/ì¸ê³µì§€ëŠ¥ìˆ˜í•™ )
                        current_dir = os.path.dirname(os.path.abspath(__file__))
                        
                        # 2. í•œ ë‹¨ê³„ ìœ„ë¡œ ì˜¬ë¼ê°€ê¸° ( .../mathzip )
                        parent_dir = os.path.dirname(current_dir)
                        
                        # 3. ê±°ê¸°ì„œ 'fonts' í´ë” ì•ˆìœ¼ë¡œ ë“¤ì–´ê°€ê¸°
                        font_path = os.path.join(parent_dir, "ê¸°íƒ€", "ë‚˜ëˆ”ê³ ë”• D2coding.ttf")
                        
                        wc = WordCloud(
                            width=400, 
                            height=300, 
                            background_color='white',
                            font_path=font_path 
                        ).generate_from_frequencies(total_counts)
                        
                        # matplotlibë¡œ ì´ë¯¸ì§€ ë³€í™˜
                        fig, ax = plt.subplots()
                        ax.imshow(wc, interpolation='bilinear')
                        ax.axis('off')
                        st.pyplot(fig)
                        
                    except Exception as e:
                        # í°íŠ¸ ì—ëŸ¬ ë“±ì´ ë°œìƒí•  ê²½ìš° ëŒ€ë¹„
                        st.error("ì›Œë“œ í´ë¼ìš°ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤ (í°íŠ¸ ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤).")
                        st.write(e)

else:
    st.info("ğŸ‘† ìƒë‹¨ì˜ í…ìŠ¤íŠ¸ ì…ë ¥ì°½ì„ ì—´ê³  ë¶„ì„í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")



