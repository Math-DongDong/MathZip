import streamlit as st
import pandas as pd
import re
from itertools import zip_longest

# ==============================================================================
# 1. í˜ì´ì§€ ì„¤ì • ë° ìŠ¤íƒ€ì¼ ì •ì˜
# ==============================================================================
st.markdown("""
<style>
    .word-badge {
        display: inline-block;
        background-color: #f0f2f6;
        color: #31333F;
        border: 1px solid #d6d6d8;
        border-radius: 15px; 
        padding: 5px 12px;
        margin: 4px;
        font-size: 14px;
        font-weight: 500;
        box-shadow: 1px 1px 3px rgba(0,0,0,0.1);
        transition: transform 0.2s;
    }
    .word-badge:hover {
        transform: scale(1.05); 
        background-color: #e0e2e6;
        border-color: #ff4b4b; 
        cursor: pointer;
    }
    .bag-container {
        border: 2px dashed #ff4b4b;
        border-radius: 10px;
        padding: 20px;
        background-color: #fff9f9;
        text-align: center;
        min-height: 200px;
    }
    th {
        text-align: center !important;
        background-color: #e8f4f8 !important;
    }
    td {
        text-align: center !important;
        font-weight: 500;
    }
</style>
""", unsafe_allow_html=True)

st.title("ğŸ§® í…ìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ìœ ìš©í•œ ì •ë³´ ì°¾ê¸°")

# ==============================================================================
# 2. ì´ˆê¸°í™”
# ==============================================================================
default_data = {
    "ë‚´ìš©": [
        "ê²½ì¹˜ê°€ ì¢‹ì•„ì„œ ì‚¬ì§„ì„ ì°ê¸°ê°€ ì¢‹ì€ ìº í•‘ì¥ì´ë¼ ì¶”ì²œí•´ìš”!",
        "ì‹œì„¤ì´ ê¹¨ë—í•˜ê³  ë·°ê°€ ì¢‹ì€ ìº í•‘ì¥ì´ì—ìš”.",
        "ì˜¨ìˆ˜ê°€ ì˜ ë‚˜ì˜¤ê³  í™”ì¥ì‹¤ì´ ê¹¨ë—í•´ì„œ ìœ„ìƒì ì´ë¼ ì¢‹ë„¤ìš”."
    ]
}

if "doc_df" not in st.session_state:
    df = pd.DataFrame(default_data, index=["A", "B", "C"])
    df.index.name = "ë¬¸ì„œëª…"
    st.session_state.doc_df = df

if "wide_token_df" not in st.session_state:
    st.session_state.wide_token_df = None

# í™•ì •ëœ ë°ì´í„° (ë‹¨ì–´ ê°€ë°© ë° ë¶„ì„ìš©)
if "confirmed_token_df" not in st.session_state:
    st.session_state.confirmed_token_df = None

# ==============================================================================
# 3. [Step 0] í…ìŠ¤íŠ¸ ë°ì´í„° ì…ë ¥
# ==============================================================================
with st.expander("ğŸ“ ë¬¸ì„œ ë°ì´í„° ì…ë ¥ ë° ìˆ˜ì • ì—´ê¸°/ë‹«ê¸°", expanded=True):    
    st.caption("â€» í–‰ì„ ì¶”ê°€í•˜ê±°ë‚˜ ì‚­ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. **ë¬¸ì„œëª…** ì—´ì€ ê° ë¬¸ì„œì˜ **ê³ ìœ  ì´ë¦„**ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.")
    input_df = st.data_editor(
        st.session_state.doc_df,
        num_rows="dynamic",
        use_container_width=True,
        key="input_editor"
    )
    
    if st.button("ğŸš€ ë°ì´í„° ì „ì²˜ë¦¬", type="primary", use_container_width=True):
        st.session_state.doc_df = input_df
        
        token_lists = []
        doc_names = []
        
        for doc_name, row in input_df.iterrows():
            content = str(row["ë‚´ìš©"])
            cleaned = re.sub(r'[^\w\s]', '', content)
            tokens = cleaned.split()
            token_lists.append(tokens)
            doc_names.append(str(doc_name))
            
        combined_tokens = list(zip_longest(*token_lists, fillvalue=None))
        wide_df = pd.DataFrame(combined_tokens, columns=doc_names)
        
        st.session_state.wide_token_df = wide_df
        st.session_state.confirmed_token_df = None # ì´ˆê¸°í™”
        st.rerun()

# ==============================================================================
# 4. ë¶„ì„ í”„ë¡œì„¸ìŠ¤
# ==============================================================================
if st.session_state.wide_token_df is not None:
    col_edit, col_bag = st.columns([0.5, 0.5], gap="large")
    with col_edit:
        st.subheader("1ï¸âƒ£ ë¶ˆìš©ì–´ ì œê±°")
        st.caption("ë‹¨ì–´ë¥¼ ììœ ë¡­ê²Œ ìˆ˜ì •í•œ ë’¤ ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
        
        # [í•µì‹¬] í¼ ì‹œì‘
        with st.form("token_edit_form", border=False):
            # í¼ ì•ˆì—ì„œëŠ” ë¦¬ë¡œë“œê°€ ë°œìƒí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
            edited_wide_df = st.data_editor(
                st.session_state.wide_token_df,
                use_container_width=True,
                height=300,
                num_rows="dynamic",
                key="wide_editor"
            )
            
            submit_btn = st.form_submit_button("ğŸ’ ë‹¨ì–´ ê°€ë°© ë§Œë“¤ê¸°", type="primary", use_container_width=True)
        
        # ë²„íŠ¼ì´ ëˆŒë¦¬ë©´ ë°ì´í„° í™•ì • ë° ì €ì¥
        if submit_btn:
            st.session_state.wide_token_df = edited_wide_df # ì—ë””í„° ìƒíƒœ ì €ì¥
            st.session_state.confirmed_token_df = edited_wide_df.copy() # ë¶„ì„ìš© í™•ì •
            st.rerun()

    # --- [Step 2] ë‹¨ì–´ ê°€ë°© ë° TF-IDF (í™•ì •ëœ ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œ) ---
    if st.session_state.confirmed_token_df is not None:
        
        # ë°ì´í„° ì¤€ë¹„
        target_df = st.session_state.confirmed_token_df
        doc_names = target_df.columns.tolist()
        tokens_by_doc = []
        all_valid_tokens_flat = []

        for doc in doc_names:
            col_tokens = target_df[doc].dropna().astype(str).tolist()
            valid_tokens = [t for t in col_tokens if t.strip() != "" and t != "None"]
            tokens_by_doc.append(valid_tokens)
            all_valid_tokens_flat.extend(valid_tokens)

        # 1-2. ì˜¤ë¥¸ìª½: ë‹¨ì–´ ê°€ë°© ì‹œê°í™”
        with col_bag:
            st.subheader("2ï¸âƒ£ ë‹¨ì–´ ê°€ë°©")
            st.caption("ë¶ˆìš©ì–´ê°€ ì œê±°ëœ ìµœì¢… ë‹¨ì–´ ì§‘í•©ì…ë‹ˆë‹¤.")
            
            all_words = sorted(list(set(all_valid_tokens_flat)))
            
            if all_words:
                html_badges = ""
                for word in all_words:
                    count = all_valid_tokens_flat.count(word)
                    html_badges += f'<span class="word-badge">{word} <small>({count})</small></span>'
                
                st.markdown(f"""
                <div class="bag-container">
                    <h4>ğŸ‘œ Vocabulary</h4>
                    <div style="margin-top: 15px;">
                        {html_badges}
                    </div>
                </div>
                """, unsafe_allow_html=True)
            else:
                st.warning("ë‹¨ì–´ ê°€ë°©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                st.stop()

        # --------------------------------------------------------------------------
        # [Step 2] ë‹¨ì–´ë¹ˆë„ (TF)
        # --------------------------------------------------------------------------
        st.divider()
        st.subheader("3ï¸âƒ£ ë‹¨ì–´ë¹ˆë„ (TF: Term Frequency)")
        st.caption("ê° ë¬¸ì„œì— ë“±ì¥í•˜ëŠ” ë‹¨ì–´ë“¤ì˜ ë¹ˆë„ìˆ˜ì…ë‹ˆë‹¤.")
        
        tf_rows = []
        for tokens in tokens_by_doc:
            counts = [tokens.count(word) for word in all_words]
            tf_rows.append(counts)
        
        df_tf = pd.DataFrame(tf_rows, columns=all_words, index=doc_names)
        st.table(df_tf,border="horizontal")

        # --------------------------------------------------------------------------
        # [Step 3] ë¬¸ì„œë¹ˆë„ (DF)
        # --------------------------------------------------------------------------
        st.subheader("4ï¸âƒ£ ë¬¸ì„œë¹ˆë„ (DF: Document Frequency)")
        st.caption("ë‹¨ì–´ë³„ë¡œ ê·¸ ë‹¨ì–´ê°€ ë“±ì¥í•˜ëŠ” ë¬¸ì„œì˜ ê°œìˆ˜ì…ë‹ˆë‹¤.")
        df_counts = []
        for word in all_words:
            count = 0
            for tokens in tokens_by_doc:
                if word in tokens:
                    count += 1
            df_counts.append(count)
            
        df_df_table = pd.DataFrame([df_counts], columns=all_words, index=["DF"])
        st.table(df_df_table,border="horizontal")

        # --------------------------------------------------------------------------
        # [Step 4] ì—­ë¬¸ì„œë¹ˆë„ (IDF)
        # --------------------------------------------------------------------------
        st.subheader("5ï¸âƒ£ ì—­ë¬¸ì„œë¹ˆë„ (IDF: Inverse Document Frequency)")
        n_docs = len(doc_names)
        
        st.latex(r"IDF = \frac{\text{ì „ì²´ ë¬¸ì„œì˜ ê°œìˆ˜}(n)}{\text{ë¬¸ì„œë¹ˆë„}(DF)}")
        st.caption(f"í˜„ì¬ ì „ì²´ ë¬¸ì„œì˜ ê°œìˆ˜(n)ëŠ” **{n_docs}**ê°œì…ë‹ˆë‹¤.")

        idf_values = []
        for df_val in df_counts:
            if df_val == 0:
                idf_values.append(0)
            else:
                idf_values.append(n_docs / df_val)
        
        idf_display = [f"{v:.2f}".rstrip('0').rstrip('.') if v != 0 else "0" for v in idf_values]
        df_idf = pd.DataFrame([idf_display], columns=all_words, index=["IDF"])
        st.table(df_idf,border="horizontal")

        # --------------------------------------------------------------------------
        # [Step 5] TF-IDF
        # --------------------------------------------------------------------------
        st.subheader("6ï¸âƒ£ TF-IDF êµ¬í•˜ê¸°")
        st.latex(r"\text{TF-IDF} = \text{TF} \times \text{IDF}")

        tfidf_rows = []
        for i in range(n_docs):
            row_vals = []
            for j in range(len(all_words)):
                tf_val = tf_rows[i][j]
                idf_val = idf_values[j]
                val = tf_val * idf_val
                row_vals.append(val)
            tfidf_rows.append(row_vals)

        df_tfidf = pd.DataFrame(tfidf_rows, columns=all_words, index=doc_names)
        df_tfidf_display = df_tfidf.applymap(lambda x: f"{x:.2f}".rstrip('0').rstrip('.') if x != 0 else "0")
        
        st.table(df_tfidf_display,border="horizontal")
        
        # [ì¸ì‚¬ì´íŠ¸]
        st.divider()
        st.subheader("ğŸ’¡ ë¶„ì„ ê²°ê³¼ ì¸ì‚¬ì´íŠ¸")
        
        for idx, doc_name in enumerate(doc_names):
            row_series = df_tfidf.iloc[idx]
            max_val = row_series.max()
            
            if max_val > 0:
                top_words = row_series[row_series == max_val].index.tolist()
                top_words_str = ", ".join([f"'{w}'" for w in top_words])
                st.success(f"ğŸ“„ **ë¬¸ì„œ {doc_name}**ì˜ í•µì‹¬ í‚¤ì›Œë“œ: **{top_words_str}** (ì ìˆ˜: {max_val:.2f})")
            else:
                st.info(f"ğŸ“„ ë¬¸ì„œ {doc_name}ì—ëŠ” íŠ¹ì§•ì ì¸ ë‹¨ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # ë²„íŠ¼ ëˆ„ë¥´ê¸° ì „ ì•ˆë‚´ ë¬¸êµ¬
        with col_bag:
            st.info("ğŸ‘ˆ ì™¼ìª½ì—ì„œ ìˆ˜ì •ì„ ë§ˆì¹˜ê³  **'ë‹¨ì–´ ê°€ë°© ë§Œë“¤ê¸°'** ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

else:
    st.info("ğŸ‘† ìƒë‹¨ì˜ ë¬¸ì„œ ì…ë ¥ì°½ì„ ì—´ê³  ë¶„ì„í•  ë¬¸ì„œ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”.")
